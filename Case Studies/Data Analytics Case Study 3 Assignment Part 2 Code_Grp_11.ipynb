{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7edb42dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------\n",
    "# Setup & config\n",
    "# -----------------\n",
    "import warnings, os\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, brier_score_loss, log_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da93e7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------\n",
    "# Speed/size knobs \n",
    "# -----------------\n",
    "CSV_PATH           = \"adjusted_dataset.csv\"\n",
    "TOP_N_COMPANIES    = 10      # analyze only the most-populated Companies for speed\n",
    "MIN_ROWS_PER_CO    = 60      # skip tiny time series\n",
    "N_SPLITS           = 3       # per-company TimeSeriesSplit folds\n",
    "N_TREES            = 100     # RF trees (keep small for speed)\n",
    "MAX_DEPTH          = 6       # RF max depth\n",
    "ALPHA              = 0.05    # significance level for tests\n",
    "COST_PER_TURN      = 0.0005  # 5 bps turnover cost in backtest\n",
    "WRITE_CSVS         = False   # set True to save outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0803586d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------\n",
    "# 1) Load & Explore Data\n",
    "# ------------------------\n",
    "assert os.path.exists(CSV_PATH), f\"Can't find {CSV_PATH}\"\n",
    "df = pd.read_csv(CSV_PATH, parse_dates=[\"Date\"])\n",
    "df = df.rename(columns=lambda c: c.strip().replace(\" \", \"_\"))\n",
    "if \"Adj_Close\" in df.columns: df = df.rename(columns={\"Adj_Close\":\"AdjClose\"})\n",
    "if \"Adj Close\" in df.columns: df = df.rename(columns={\"Adj Close\":\"AdjClose\"})\n",
    "if \"Close\" in df.columns and \"AdjClose\" not in df.columns:\n",
    "    df = df.rename(columns={\"Close\":\"AdjClose\"})\n",
    "\n",
    "required = {\"Company\",\"Date\",\"Open\",\"AdjClose\"}\n",
    "missing = required - set(df.columns)\n",
    "assert not missing, f\"Missing required columns: {missing}\"\n",
    "\n",
    "df = df.dropna(subset=list(required)).copy()\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"], errors=\"coerce\").dt.tz_localize(None)\n",
    "df = df[(df[\"Open\"]>0) & (df[\"AdjClose\"]>0)].copy()\n",
    "df = df.sort_values([\"Company\",\"Date\"]).reset_index(drop=True)\n",
    "\n",
    "# focus on top-N companies to keep it fast\n",
    "top_companies = df[\"Company\"].value_counts().nlargest(TOP_N_COMPANIES).index\n",
    "df = df[df[\"Company\"].isin(top_companies)].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e084ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# 2) Features (NO leakage)\n",
    "# -----------------------\n",
    "def add_features(g):\n",
    "    g = g.sort_values(\"Date\").copy()\n",
    "    g[\"prev_adj\"]      = g[\"AdjClose\"].shift(1)\n",
    "    g[\"daily_ret\"]     = (g[\"AdjClose\"] - g[\"prev_adj\"]) / g[\"prev_adj\"]         # close→close\n",
    "    g[\"intraday_ret\"]  = (g[\"AdjClose\"] - g[\"Open\"])     / g[\"Open\"]             # open→close\n",
    "    g[\"overnight_gap\"] = (g[\"Open\"]      - g[\"prev_adj\"]) / g[\"prev_adj\"]        # prev close→open\n",
    "\n",
    "    if \"Volume\" in g.columns:\n",
    "        roll = g[\"Volume\"].rolling(20, min_periods=5)\n",
    "        g[\"vol_roll_mean\"] = roll.mean()\n",
    "        g[\"vol_roll_std\"]  = roll.std()\n",
    "        g[\"vol_zscore\"]    = (g[\"Volume\"] - g[\"vol_roll_mean\"]) / g[\"vol_roll_std\"]\n",
    "        g[\"vol_spike\"]     = (g[\"vol_zscore\"] > 2).astype(int)\n",
    "    else:\n",
    "        g[\"vol_zscore\"] = np.nan\n",
    "        g[\"vol_spike\"]  = 0\n",
    "\n",
    "    # anti-leak: only use volume info known BEFORE today's intraday move\n",
    "    g[\"vol_zscore_lag1\"] = g[\"vol_zscore\"].shift(1)\n",
    "    g[\"vol_spike_lag1\"]  = g[\"vol_spike\"].shift(1).fillna(0).astype(int)\n",
    "\n",
    "    g[\"weekday\"]    = g[\"Date\"].dt.day_name()\n",
    "    g[\"month\"]      = g[\"Date\"].dt.month_name()\n",
    "    g[\"target_up\"]  = (g[\"intraday_ret\"] > 0).astype(int)\n",
    "    return g\n",
    "\n",
    "df = df.groupby(\"Company\", group_keys=False).apply(add_features).reset_index(drop=True)\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df = df.dropna(subset=[\"daily_ret\",\"intraday_ret\",\"overnight_gap\"]).copy()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd0e5934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================\n",
    "# 3) RQ1 — Similar return profiles? (variance/tails)\n",
    "# ======================================================================\n",
    "rq1_summary = (df.groupby(\"Company\")[\"daily_ret\"]\n",
    "                 .agg(count=\"count\", mean=\"mean\", var=\"var\", std=\"std\")\n",
    "                 .assign(\n",
    "                     kurtosis = df.groupby(\"Company\")[\"daily_ret\"].apply(pd.Series.kurtosis),\n",
    "                     pct_extreme = df.groupby(\"Company\")[\"daily_ret\"].apply(\n",
    "                         lambda x: (x.abs() > (3*x.std())).mean()*100\n",
    "                     ))\n",
    "               .sort_values(\"var\", ascending=False))\n",
    "\n",
    "groups = [g[\"daily_ret\"].values for _, g in df.groupby(\"Company\") if len(g)>=MIN_ROWS_PER_CO]\n",
    "rq1_levene_p  = stats.levene(*groups, center=\"median\").pvalue if len(groups)>=2 else np.nan\n",
    "rq1_fligner_p = stats.fligner(*groups).pvalue if len(groups)>=2 else np.nan\n",
    "rq1_reject = ((not np.isnan(rq1_levene_p) and rq1_levene_p<ALPHA) or\n",
    "              (not np.isnan(rq1_fligner_p) and rq1_fligner_p<ALPHA))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3117a792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================\n",
    "# 4) RQ2 — Gaps → intraday direction (association + prediction)\n",
    "# ======================================================================\n",
    "def sign_label(x): return \"pos\" if x>0 else (\"neg\" if x<0 else \"zero\")\n",
    "df[\"gap_sign\"] = df[\"overnight_gap\"].apply(sign_label)\n",
    "ct = pd.crosstab(df[\"gap_sign\"], df[\"target_up\"])\n",
    "rq2_chi2_p = stats.chi2_contingency(ct)[1] if ct.values.sum()>0 else np.nan\n",
    "\n",
    "# Logit (pooled, inference; uses lagged volume to avoid leakage)\n",
    "logit_df = df.dropna(subset=[\"target_up\",\"overnight_gap\",\"vol_zscore_lag1\"]).copy()\n",
    "logit = smf.logit(\"target_up ~ overnight_gap + vol_zscore_lag1\", data=logit_df).fit(disp=False)\n",
    "rq2_logit_params = logit.params.copy()\n",
    "rq2_logit_pvals  = logit.pvalues.copy()\n",
    "rq2_logit_or     = np.exp(rq2_logit_params)\n",
    "rq2_support_assoc = (rq2_logit_pvals.get(\"overnight_gap\",1.0) < ALPHA) and (rq2_logit_params.get(\"overnight_gap\",0) > 0)\n",
    "\n",
    "# ---------- RQ2 ML: per-company, EXPLICIT TimeSeriesSplit ----------\n",
    "features = [\"overnight_gap\",\"vol_zscore_lag1\"]\n",
    "def eval_company_ml(g):\n",
    "    g = g.dropna(subset=features+[\"target_up\"]).copy()\n",
    "    if len(g) < MIN_ROWS_PER_CO:\n",
    "        return pd.Series({\"AUC\":np.nan,\"ACC\":np.nan,\"Brier\":np.nan,\"LogLoss\":np.nan,\"n\":len(g)})\n",
    "\n",
    "    X = g[features].values\n",
    "    y = g[\"target_up\"].values\n",
    "    n_splits = min(N_SPLITS, max(2, len(g)//MIN_ROWS_PER_CO))\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "\n",
    "    aucs, accs, briers, logs = [], [], [], []\n",
    "    rf = RandomForestClassifier(n_estimators=N_TREES, max_depth=MAX_DEPTH, random_state=42)\n",
    "\n",
    "    for tr_idx, te_idx in tscv.split(X):\n",
    "        # explicit splits\n",
    "        X_train, X_test = X[tr_idx], X[te_idx]\n",
    "        y_train, y_test = y[tr_idx], y[te_idx]\n",
    "\n",
    "        rf.fit(X_train, y_train)\n",
    "        p = rf.predict_proba(X_test)[:,1]\n",
    "        preds = (p>=0.5).astype(int)\n",
    "\n",
    "        aucs.append(roc_auc_score(y_test, p))\n",
    "        accs.append(accuracy_score(y_test, preds))\n",
    "        briers.append(brier_score_loss(y_test, p))\n",
    "        logs.append(log_loss(y_test, np.clip(p,1e-6,1-1e-6)))\n",
    "\n",
    "    return pd.Series({\n",
    "        \"AUC\":   np.mean(aucs),\n",
    "        \"ACC\":   np.mean(accs),\n",
    "        \"Brier\": np.mean(briers),\n",
    "        \"LogLoss\": np.mean(logs),\n",
    "        \"n\": len(g)\n",
    "    })\n",
    "\n",
    "eval_by_co = df.groupby(\"Company\", group_keys=False).apply(eval_company_ml)\n",
    "ml_summary = eval_by_co[[\"AUC\",\"ACC\",\"Brier\",\"LogLoss\"]].describe().T\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cb406bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================\n",
    "# 5) RQ3 — (Lagged) volume vs. move size\n",
    "# ======================================================================\n",
    "rq3_df = df.dropna(subset=[\"intraday_ret\",\"vol_zscore_lag1\"]).copy()\n",
    "rq3_df[\"abs_intraday\"] = rq3_df[\"intraday_ret\"].abs()\n",
    "\n",
    "ols = smf.ols(\"abs_intraday ~ vol_zscore_lag1\", data=rq3_df).fit()\n",
    "rq3_beta = ols.params.get(\"vol_zscore_lag1\", np.nan)\n",
    "rq3_pval = ols.pvalues.get(\"vol_zscore_lag1\", np.nan)\n",
    "\n",
    "spike = rq3_df[rq3_df[\"vol_spike_lag1\"]==1][\"abs_intraday\"]\n",
    "normal = rq3_df[rq3_df[\"vol_spike_lag1\"]==0][\"abs_intraday\"]\n",
    "rq3_mw_p = stats.mannwhitneyu(spike, normal, alternative=\"two-sided\").pvalue \\\n",
    "           if (len(spike)>=10 and len(normal)>=10) else np.nan\n",
    "rq3_reject = ((rq3_pval<ALPHA and rq3_beta>0) or (not np.isnan(rq3_mw_p) and rq3_mw_p<ALPHA))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e5c8c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================\n",
    "# 6) RQ4 — Seasonality (weekday/month), normalized by company\n",
    "# ======================================================================\n",
    "def z_by_company(s):\n",
    "    sd = s.std(ddof=0)\n",
    "    return (s - s.mean()) / (sd if sd>0 else 1.0)\n",
    "df[\"daily_ret_z\"] = df.groupby(\"Company\")[\"daily_ret\"].transform(z_by_company)\n",
    "\n",
    "wk_groups = [g[\"daily_ret_z\"].dropna().values for _, g in df.groupby(\"weekday\") if len(g)>=30]\n",
    "rq4_kw_weekday_p = stats.kruskal(*wk_groups).pvalue if len(wk_groups)>=2 else np.nan\n",
    "\n",
    "mo_groups = [g[\"daily_ret_z\"].dropna().values for _, g in df.groupby(\"month\") if len(g)>=30]\n",
    "rq4_kw_month_p = stats.kruskal(*mo_groups).pvalue if len(mo_groups)>=2 else np.nan\n",
    "\n",
    "rq4_reject = ((not np.isnan(rq4_kw_weekday_p) and rq4_kw_weekday_p<ALPHA) or\n",
    "              (not np.isnan(rq4_kw_month_p)   and rq4_kw_month_p  <ALPHA))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b938b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================\n",
    "# 7) 80/20 chronological HOLDOUT for RQ2 prediction (global + per-company)\n",
    "# ======================================================================\n",
    "needed_cols = features + [\"target_up\",\"Date\",\"Company\"]\n",
    "hold_df = df.dropna(subset=needed_cols).copy().sort_values([\"Date\",\"Company\"])\n",
    "cutoff_date = hold_df[\"Date\"].quantile(0.80)\n",
    "train = hold_df[hold_df[\"Date\"] <= cutoff_date].copy()\n",
    "test  = hold_df[hold_df[\"Date\"] >  cutoff_date].copy()\n",
    "\n",
    "# Global Logit\n",
    "g_logit = smf.logit(\"target_up ~ overnight_gap + vol_zscore_lag1\", data=train).fit(disp=False)\n",
    "p_logit  = g_logit.predict(test[features])\n",
    "pred_l   = (p_logit>=0.5).astype(int)\n",
    "logit_auc = roc_auc_score(test[\"target_up\"], p_logit)\n",
    "logit_acc = accuracy_score(test[\"target_up\"], pred_l)\n",
    "logit_brier = brier_score_loss(test[\"target_up\"], p_logit)\n",
    "logit_ll = log_loss(test[\"target_up\"], np.clip(p_logit,1e-6,1-1e-6))\n",
    "\n",
    "# Global RF\n",
    "rf_global = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "rf_global.fit(train[features], train[\"target_up\"])\n",
    "p_rf  = rf_global.predict_proba(test[features])[:,1]\n",
    "pred_r= (p_rf>=0.5).astype(int)\n",
    "rf_auc = roc_auc_score(test[\"target_up\"], p_rf)\n",
    "rf_acc = accuracy_score(test[\"target_up\"], pred_r)\n",
    "rf_brier = brier_score_loss(test[\"target_up\"], p_rf)\n",
    "rf_ll = log_loss(test[\"target_up\"], np.clip(p_rf,1e-6,1-1e-6))\n",
    "\n",
    "# Per-company 80/20 (chronological) summary\n",
    "def per_company_holdout(g):\n",
    "    g = g.dropna(subset=needed_cols).sort_values(\"Date\")\n",
    "    n = len(g)\n",
    "    if n < MIN_ROWS_PER_CO: \n",
    "        return pd.Series({\"AUC_Logit\":np.nan,\"ACC_Logit\":np.nan,\"AUC_RF\":np.nan,\"ACC_RF\":np.nan,\"n\":n})\n",
    "    cut = g[\"Date\"].iloc[int(np.floor(0.8*n))]\n",
    "    tr, te = g[g[\"Date\"]<=cut], g[g[\"Date\"]>cut]\n",
    "    if len(te)<10 or len(tr)<30:\n",
    "        return pd.Series({\"AUC_Logit\":np.nan,\"ACC_Logit\":np.nan,\"AUC_RF\":np.nan,\"ACC_RF\":np.nan,\"n\":n})\n",
    "    # Logit\n",
    "    try:\n",
    "        m = smf.logit(\"target_up ~ overnight_gap + vol_zscore_lag1\", data=tr).fit(disp=False)\n",
    "        p = m.predict(te[features])\n",
    "        auc_l = roc_auc_score(te[\"target_up\"], p)\n",
    "        acc_l = accuracy_score(te[\"target_up\"], (p>=0.5).astype(int))\n",
    "    except Exception:\n",
    "        auc_l, acc_l = np.nan, np.nan\n",
    "    # RF\n",
    "    try:\n",
    "        r = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "        r.fit(tr[features], tr[\"target_up\"])\n",
    "        p2 = r.predict_proba(te[features])[:, 1]\n",
    "        auc_r = roc_auc_score(te[\"target_up\"], p2)\n",
    "        acc_r = accuracy_score(te[\"target_up\"], (p2>=0.5).astype(int))\n",
    "    except Exception:\n",
    "        auc_r, acc_r = np.nan, np.nan\n",
    "    return pd.Series({\"AUC_Logit\":auc_l,\"ACC_Logit\":acc_l,\"AUC_RF\":auc_r,\"ACC_RF\":acc_r,\"n\":n})\n",
    "\n",
    "perco_eval = hold_df.groupby(\"Company\", group_keys=False).apply(per_company_holdout)\n",
    "perco_med  = perco_eval[[\"AUC_Logit\",\"ACC_Logit\",\"AUC_RF\",\"ACC_RF\",\"n\"]].median(numeric_only=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5ddd930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================\n",
    "# 8) Portfolio-correct baseline backtest (naive gap rule)\n",
    "# ======================================================================\n",
    "bt = df.sort_values([\"Company\",\"Date\"]).copy()\n",
    "bt[\"side_rule\"] = (bt[\"overnight_gap\"] > 0).astype(int)\n",
    "bt[\"ret_rule\"]  = np.where(bt[\"side_rule\"]==1, bt[\"intraday_ret\"], -bt[\"intraday_ret\"])\n",
    "bt[\"turnover\"]  = bt.groupby(\"Company\")[\"side_rule\"].diff().abs().fillna(0)\n",
    "by_day = bt.groupby(\"Date\", as_index=True)\n",
    "daily_ret   = by_day[\"ret_rule\"].mean().fillna(0)\n",
    "daily_costs = (by_day[\"turnover\"].mean() * COST_PER_TURN).fillna(0)\n",
    "net_daily   = (daily_ret - daily_costs).fillna(0)\n",
    "equity = (1+net_daily).cumprod()\n",
    "def CAGR(eq, ann=252): return (eq.iloc[-1])**(ann/len(eq)) - 1 if len(eq)>0 else np.nan\n",
    "def max_dd(eq): return (eq/eq.cummax()-1).min() if len(eq)>0 else np.nan\n",
    "bt_cagr, bt_sharpe, bt_mdd = CAGR(equity), (np.sqrt(252)*net_daily.mean()/net_daily.std() if net_daily.std()>0 else np.nan), max_dd(equity)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e17bd069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========================================================================================\n",
      "RESULTS & DECISIONS (α = 0.05)\n",
      "==========================================================================================\n",
      "\n",
      "[RQ1] Similar return profiles?\n",
      "  Levene p = 7.648e-57\n",
      "  Fligner p = 5.768e-161\n",
      "  Decision: Reject H0? YES\n",
      "  Top 5 by variance (var, kurtosis, %>|3σ|):\n",
      "              var    kurtosis  pct_extreme\n",
      "Company                                   \n",
      "ZS       0.005535  252.781354     0.795545\n",
      "ADBE     0.001704  129.191945     0.795545\n",
      "AAPL     0.001414  196.285301     0.636436\n",
      "ABEV     0.001080   39.296411     1.113763\n",
      "ACGL     0.001047  119.978017     1.272872 \n",
      "\n",
      "[RQ2] Do overnight gaps predict intraday direction?\n",
      "  Chi-square p (gap_sign vs up): 0.1517\n",
      "  Logit coefficients (pooled, leak-safe):\n",
      "             Intercept: beta= 0.1036, OR= 1.109, p=7.011e-09\n",
      "         overnight_gap: beta=-0.8598, OR= 0.423, p=0.1254\n",
      "       vol_zscore_lag1: beta= 0.0126, OR= 1.013, p=0.461\n",
      "  Assoc. Decision (Logit 'overnight_gap' >0 & p<α): NO\n",
      "\n",
      "  ML (per-company TimeSeriesSplit, explicit train/test) summary:\n",
      "         count      mean       std       min       50%       max\n",
      "AUC       10.0  0.492766  0.021128  0.459497  0.493646  0.522619\n",
      "ACC       10.0  0.504260  0.017034  0.480298  0.502130  0.533546\n",
      "Brier     10.0  0.259351  0.003447  0.250997  0.259943  0.262808\n",
      "LogLoss   10.0  0.713969  0.007561  0.695704  0.715223  0.723262\n",
      "\n",
      "  80/20 GLOBAL holdout:\n",
      "    LOGIT   AUC=0.478  ACC=0.527  Brier=0.2492  LogLoss=0.6916\n",
      "    RF      AUC=0.501     ACC=0.514     Brier=0.2849     LogLoss=0.7830\n",
      "  80/20 PER-COMPANY holdout (medians across tickers):\n",
      "AUC_Logit      0.527744\n",
      "ACC_Logit      0.535714\n",
      "AUC_RF         0.498237\n",
      "ACC_RF         0.517857\n",
      "n            425.000000\n",
      "dtype: float64\n",
      "\n",
      "  Predictive Decision: Reject H0? NO\n",
      "\n",
      "[RQ3] Do (lagged) volume spikes lead to larger moves?\n",
      "  OLS beta(vol_zscore_lag1)=0.0013, p=3.387e-32\n",
      "  Mann–Whitney p (spike_prev vs none) = 4.588e-10\n",
      "  Decision: Reject H0? YES\n",
      "\n",
      "[RQ4] Seasonality (weekday/month) after per-company normalization:\n",
      "  Weekday Kruskal–Wallis p = 0.0152\n",
      "  Month   Kruskal–Wallis p = 1.029e-07\n",
      "  Decision: Reject H0? YES\n",
      "\n",
      "[Baseline backtest] Naive equal-weight gap rule (incl. simple costs)\n",
      "  CAGR=-10.21%  Sharpe=-0.72  MaxDD=-26.35%\n"
     ]
    }
   ],
   "source": [
    "# ======================================================================\n",
    "# 9) Decision-focused report: Accept/Reject each H0 + conclusion\n",
    "# ======================================================================\n",
    "def yn(b): return \"YES\" if b else \"NO\"\n",
    "\n",
    "print(\"\\n\" + \"=\"*90)\n",
    "print(\"RESULTS & DECISIONS (α = 0.05)\")\n",
    "print(\"=\"*90)\n",
    "\n",
    "# RQ1\n",
    "print(\"\\n[RQ1] Similar return profiles?\")\n",
    "print(f\"  Levene p = {rq1_levene_p:.4g}\" if not np.isnan(rq1_levene_p) else \"  Levene: N/A\")\n",
    "print(f\"  Fligner p = {rq1_fligner_p:.4g}\" if not np.isnan(rq1_fligner_p) else \"  Fligner: N/A\")\n",
    "print(f\"  Decision: Reject H0? {yn(rq1_reject)}\")\n",
    "if not rq1_summary.empty:\n",
    "    print(\"  Top 5 by variance (var, kurtosis, %>|3σ|):\")\n",
    "    print(rq1_summary[[\"var\",\"kurtosis\",\"pct_extreme\"]].head(5), \"\\n\")\n",
    "\n",
    "# RQ2\n",
    "print(\"[RQ2] Do overnight gaps predict intraday direction?\")\n",
    "print(f\"  Chi-square p (gap_sign vs up): {rq2_chi2_p:.4g}\" if not np.isnan(rq2_chi2_p) else \"  Chi-square: N/A\")\n",
    "print(\"  Logit coefficients (pooled, leak-safe):\")\n",
    "for k in rq2_logit_params.index:\n",
    "    print(f\"    {k:>18}: beta={rq2_logit_params[k]: .4f}, OR={rq2_logit_or[k]: .3f}, p={rq2_logit_pvals[k]:.4g}\")\n",
    "print(f\"  Assoc. Decision (Logit 'overnight_gap' >0 & p<α): {yn(rq2_support_assoc)}\")\n",
    "\n",
    "print(\"\\n  ML (per-company TimeSeriesSplit, explicit train/test) summary:\")\n",
    "print(ml_summary[[\"count\",\"mean\",\"std\",\"min\",\"50%\",\"max\"]])\n",
    "\n",
    "print(\"\\n  80/20 GLOBAL holdout:\")\n",
    "print(f\"    LOGIT   AUC={logit_auc:.3f}  ACC={logit_acc:.3f}  Brier={logit_brier:.4f}  LogLoss={logit_ll:.4f}\")\n",
    "print(f\"    RF      AUC={rf_auc:.3f}     ACC={rf_acc:.3f}     Brier={rf_brier:.4f}     LogLoss={rf_ll:.4f}\")\n",
    "print(\"  80/20 PER-COMPANY holdout (medians across tickers):\")\n",
    "print(perco_med)\n",
    "\n",
    "# Decide RQ2 predictability: both statistical association AND some predictive edge\n",
    "rq2_predictive = (rq2_support_assoc and (rf_auc >= 0.55 or logit_auc >= 0.55))\n",
    "print(f\"\\n  Predictive Decision: Reject H0? {yn(rq2_predictive)}\")\n",
    "\n",
    "# RQ3\n",
    "print(\"\\n[RQ3] Do (lagged) volume spikes lead to larger moves?\")\n",
    "print(f\"  OLS beta(vol_zscore_lag1)={rq3_beta:.4f}, p={rq3_pval:.4g}\")\n",
    "print(f\"  Mann–Whitney p (spike_prev vs none) = {rq3_mw_p:.4g}\" if not np.isnan(rq3_mw_p) else \"  Mann–Whitney: N/A\")\n",
    "print(f\"  Decision: Reject H0? {yn(rq3_reject)}\")\n",
    "\n",
    "# RQ4\n",
    "print(\"\\n[RQ4] Seasonality (weekday/month) after per-company normalization:\")\n",
    "print(f\"  Weekday Kruskal–Wallis p = {rq4_kw_weekday_p:.4g}\" if not np.isnan(rq4_kw_weekday_p) else \"  Weekday: N/A\")\n",
    "print(f\"  Month   Kruskal–Wallis p = {rq4_kw_month_p:.4g}\"   if not np.isnan(rq4_kw_month_p)   else \"  Month: N/A\")\n",
    "print(f\"  Decision: Reject H0? {yn(rq4_reject)}\")\n",
    "\n",
    "# Backtest\n",
    "def sharpe(daily):\n",
    "    sd = daily.std()\n",
    "    return np.sqrt(252)*daily.mean()/sd if sd>0 else np.nan\n",
    "print(\"\\n[Baseline backtest] Naive equal-weight gap rule (incl. simple costs)\")\n",
    "print(f\"  CAGR={CAGR(equity):.2%}  Sharpe={sharpe(net_daily):.2f}  MaxDD={max_dd(equity):.2%}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "299320b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "FINAL CONCLUSION:\n",
      "  1. Return profiles differ across companies—tail risk/variance is not uniform.\n",
      "  2. Overnight gaps show limited/mixed predictive power across the holdout and companies.\n",
      "  3. Higher prior volume is associated with larger subsequent intraday moves.\n",
      "  4. Some seasonal (weekday/month) effects exist after normalizing by company.\n",
      "  5. Baseline, cost-aware gap rule shows baseline-level performance; more signal engineering and tuning are needed for stronger economics.\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Overall project conclusion\n",
    "print(\"\\n\" + \"-\"*90)\n",
    "conclusions = []\n",
    "if rq1_reject:\n",
    "    conclusions.append(\"Return profiles differ across companies—tail risk/variance is not uniform.\")\n",
    "else:\n",
    "    conclusions.append(\"No strong evidence that company return profiles materially differ in variance/tails.\")\n",
    "\n",
    "if rq2_predictive:\n",
    "    conclusions.append(\"Overnight gaps provide statistically significant AND modestly predictive information for intraday direction.\")\n",
    "else:\n",
    "    conclusions.append(\"Overnight gaps show limited/mixed predictive power across the holdout and companies.\")\n",
    "\n",
    "if rq3_reject:\n",
    "    conclusions.append(\"Higher prior volume is associated with larger subsequent intraday moves.\")\n",
    "else:\n",
    "    conclusions.append(\"No robust link between prior-day volume spikes and next-day move size was detected.\")\n",
    "\n",
    "if rq4_reject:\n",
    "    conclusions.append(\"Some seasonal (weekday/month) effects exist after normalizing by company.\")\n",
    "else:\n",
    "    conclusions.append(\"No compelling aggregate seasonal effects detected.\")\n",
    "\n",
    "conclusions.append(\"Baseline, cost-aware gap rule shows baseline-level performance; more signal engineering and tuning are needed for stronger economics.\")\n",
    "\n",
    "print(\"FINAL CONCLUSION:\")\n",
    "for i, c in enumerate(conclusions, 1):\n",
    "    print(f\"  {i}. {c}\")\n",
    "print(\"-\"*90)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
